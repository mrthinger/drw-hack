{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from config import DEVICE, STATEMENT_FILE\n",
    "from graphprompt import gprompt_analyze\n",
    "from models import Observation\n",
    "import polars as pl\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at infgrad/jasper_en_vision_language_v1 were not used when initializing JasperVL: {'vision_model.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.25.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.26.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.vision_model.head.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.vision_model.head.layernorm.weight', 'vision_model.vision_model.head.attention.in_proj_bias', 'vision_model.vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.26.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.25.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.24.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.vision_model.embeddings.patch_embedding.weight', 'vision_model.vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.26.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.26.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.24.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.25.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.25.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.vision_model.post_layernorm.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.26.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.vision_model.head.attention.in_proj_weight', 'vision_model.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.vision_model.post_layernorm.bias', 'vision_model.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.25.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.vision_model.embeddings.position_embedding.weight', 'vision_model.vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.vision_model.head.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.vision_model.head.probe', 'vision_model.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.vision_model.head.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.25.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.25.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.25.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.vision_model.head.attention.out_proj.weight', 'vision_model.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.26.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.26.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.24.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.24.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.24.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.24.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.vision_model.head.layernorm.bias', 'vision_model.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'vision_model.vision_model.head.attention.out_proj.bias', 'vision_model.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.24.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.vision_model.head.mlp.fc1.bias', 'vision_model.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.vision_model.embeddings.patch_embedding.bias', 'vision_model.vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.vision_model.encoder.layers.26.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.24.mlp.fc2.weight', 'vision_model.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.vision_model.encoder.layers.2.mlp.fc2.weight'}\n",
      "- This IS expected if you are initializing JasperVL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JasperVL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    \"infgrad/jasper_en_vision_language_v1\",\n",
    "    trust_remote_code=True,\n",
    "    device=DEVICE,\n",
    "    config_kwargs={\n",
    "        \"is_text_encoder\": True,\n",
    "        \"vector_dim\": 1024,\n",
    "        \"use_memory_efficient_attention\": False,\n",
    "        \"unpad_inputs\": False,\n",
    "    },\n",
    ")\n",
    "model.max_seq_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (442, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>Release Date</th><th>Type</th><th>Text</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2024-12-18&quot;</td><td>&quot;2025-01-08&quot;</td><td>&quot;Minute&quot;</td><td>&quot;Minutes of the Federal Open Ma…</td></tr><tr><td>&quot;2024-12-18&quot;</td><td>&quot;2024-12-18&quot;</td><td>&quot;Statement&quot;</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>&quot;2024-11-07&quot;</td><td>&quot;2024-11-26&quot;</td><td>&quot;Minute&quot;</td><td>&quot;Minutes of the Federal Open Ma…</td></tr><tr><td>&quot;2024-11-07&quot;</td><td>&quot;2024-11-07&quot;</td><td>&quot;Statement&quot;</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>&quot;2024-09-18&quot;</td><td>&quot;2024-09-18&quot;</td><td>&quot;Statement&quot;</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2000-05-16&quot;</td><td>&quot;2000-05-16&quot;</td><td>&quot;Statement&quot;</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>&quot;2000-03-21&quot;</td><td>&quot;2000-05-18&quot;</td><td>&quot;Minute&quot;</td><td>&quot;Minutes of the Federal Open Ma…</td></tr><tr><td>&quot;2000-03-21&quot;</td><td>&quot;2000-03-21&quot;</td><td>&quot;Statement&quot;</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>&quot;2000-02-02&quot;</td><td>&quot;2000-03-23&quot;</td><td>&quot;Minute&quot;</td><td>&quot;Minutes of the Federal Open Ma…</td></tr><tr><td>&quot;2000-02-02&quot;</td><td>&quot;2000-02-02&quot;</td><td>&quot;Statement&quot;</td><td>&quot;The Federal Open Market Commit…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (442, 4)\n",
       "┌────────────┬──────────────┬───────────┬─────────────────────────────────┐\n",
       "│ Date       ┆ Release Date ┆ Type      ┆ Text                            │\n",
       "│ ---        ┆ ---          ┆ ---       ┆ ---                             │\n",
       "│ str        ┆ str          ┆ str       ┆ str                             │\n",
       "╞════════════╪══════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ 2024-12-18 ┆ 2025-01-08   ┆ Minute    ┆ Minutes of the Federal Open Ma… │\n",
       "│ 2024-12-18 ┆ 2024-12-18   ┆ Statement ┆ Recent indicators suggest that… │\n",
       "│ 2024-11-07 ┆ 2024-11-26   ┆ Minute    ┆ Minutes of the Federal Open Ma… │\n",
       "│ 2024-11-07 ┆ 2024-11-07   ┆ Statement ┆ Recent indicators suggest that… │\n",
       "│ 2024-09-18 ┆ 2024-09-18   ┆ Statement ┆ Recent indicators suggest that… │\n",
       "│ …          ┆ …            ┆ …         ┆ …                               │\n",
       "│ 2000-05-16 ┆ 2000-05-16   ┆ Statement ┆ The Federal Open Market Commit… │\n",
       "│ 2000-03-21 ┆ 2000-05-18   ┆ Minute    ┆ Minutes of the Federal Open Ma… │\n",
       "│ 2000-03-21 ┆ 2000-03-21   ┆ Statement ┆ The Federal Open Market Commit… │\n",
       "│ 2000-02-02 ┆ 2000-03-23   ┆ Minute    ┆ Minutes of the Federal Open Ma… │\n",
       "│ 2000-02-02 ┆ 2000-02-02   ┆ Statement ┆ The Federal Open Market Commit… │\n",
       "└────────────┴──────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_fomc = pl.read_csv('./data/raw/communications.csv')\n",
    "raw_fomc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (212, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>text</th></tr><tr><td>datetime[μs]</td><td>str</td></tr></thead><tbody><tr><td>2000-02-02 00:00:00</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>2000-03-21 00:00:00</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>2000-05-16 00:00:00</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>2000-06-28 00:00:00</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>2000-08-22 00:00:00</td><td>&quot;The Federal Open Market Commit…</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2024-06-12 00:00:00</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>2024-07-31 00:00:00</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>2024-09-18 00:00:00</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>2024-11-07 00:00:00</td><td>&quot;Recent indicators suggest that…</td></tr><tr><td>2024-12-18 00:00:00</td><td>&quot;Recent indicators suggest that…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (212, 2)\n",
       "┌─────────────────────┬─────────────────────────────────┐\n",
       "│ date                ┆ text                            │\n",
       "│ ---                 ┆ ---                             │\n",
       "│ datetime[μs]        ┆ str                             │\n",
       "╞═════════════════════╪═════════════════════════════════╡\n",
       "│ 2000-02-02 00:00:00 ┆ The Federal Open Market Commit… │\n",
       "│ 2000-03-21 00:00:00 ┆ The Federal Open Market Commit… │\n",
       "│ 2000-05-16 00:00:00 ┆ The Federal Open Market Commit… │\n",
       "│ 2000-06-28 00:00:00 ┆ The Federal Open Market Commit… │\n",
       "│ 2000-08-22 00:00:00 ┆ The Federal Open Market Commit… │\n",
       "│ …                   ┆ …                               │\n",
       "│ 2024-06-12 00:00:00 ┆ Recent indicators suggest that… │\n",
       "│ 2024-07-31 00:00:00 ┆ Recent indicators suggest that… │\n",
       "│ 2024-09-18 00:00:00 ┆ Recent indicators suggest that… │\n",
       "│ 2024-11-07 00:00:00 ┆ Recent indicators suggest that… │\n",
       "│ 2024-12-18 00:00:00 ┆ Recent indicators suggest that… │\n",
       "└─────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fomc = (\n",
    "    raw_fomc.filter(pl.col(\"Type\").eq(\"Statement\"))\n",
    "    .with_columns(pl.col(\"Release Date\").str.to_datetime())\n",
    "    .select(pl.col(\"Release Date\").alias('date'), pl.col(\"Text\").alias(\"text\"))\n",
    "    .sort(\"date\")\n",
    ")\n",
    "fomc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (164, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>text</th><th>filename</th></tr><tr><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2000-01-01 00:00:00</td><td>&quot;Reports from most Federal Rese…</td><td>&quot;./data/raw/beige-book/2000/01/…</td></tr><tr><td>2000-03-01 00:00:00</td><td>&quot;Reports from the twelve Federa…</td><td>&quot;./data/raw/beige-book/2000/03/…</td></tr><tr><td>2000-05-01 00:00:00</td><td>&quot;Reports from the twelve Federa…</td><td>&quot;./data/raw/beige-book/2000/05/…</td></tr><tr><td>2000-06-01 00:00:00</td><td>&quot;Reports from the Federal Reser…</td><td>&quot;./data/raw/beige-book/2000/06/…</td></tr><tr><td>2000-08-01 00:00:00</td><td>&quot;The information collected for …</td><td>&quot;./data/raw/beige-book/2000/08/…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2019-11-01 00:00:00</td><td>&quot;This report was prepared at th…</td><td>&quot;./data/raw/beige-book/2019/11/…</td></tr><tr><td>2020-01-01 00:00:00</td><td>&quot;This report was prepared at th…</td><td>&quot;./data/raw/beige-book/2020/01/…</td></tr><tr><td>2020-03-01 00:00:00</td><td>&quot;This report was prepared at th…</td><td>&quot;./data/raw/beige-book/2020/03/…</td></tr><tr><td>2020-04-01 00:00:00</td><td>&quot;This report was prepared at th…</td><td>&quot;./data/raw/beige-book/2020/04/…</td></tr><tr><td>2020-05-01 00:00:00</td><td>&quot;Overall Economic Activity Econ…</td><td>&quot;./data/raw/beige-book/2020/05/…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (164, 3)\n",
       "┌─────────────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ date                ┆ text                            ┆ filename                        │\n",
       "│ ---                 ┆ ---                             ┆ ---                             │\n",
       "│ datetime[μs]        ┆ str                             ┆ str                             │\n",
       "╞═════════════════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ 2000-01-01 00:00:00 ┆ Reports from most Federal Rese… ┆ ./data/raw/beige-book/2000/01/… │\n",
       "│ 2000-03-01 00:00:00 ┆ Reports from the twelve Federa… ┆ ./data/raw/beige-book/2000/03/… │\n",
       "│ 2000-05-01 00:00:00 ┆ Reports from the twelve Federa… ┆ ./data/raw/beige-book/2000/05/… │\n",
       "│ 2000-06-01 00:00:00 ┆ Reports from the Federal Reser… ┆ ./data/raw/beige-book/2000/06/… │\n",
       "│ 2000-08-01 00:00:00 ┆ The information collected for … ┆ ./data/raw/beige-book/2000/08/… │\n",
       "│ …                   ┆ …                               ┆ …                               │\n",
       "│ 2019-11-01 00:00:00 ┆ This report was prepared at th… ┆ ./data/raw/beige-book/2019/11/… │\n",
       "│ 2020-01-01 00:00:00 ┆ This report was prepared at th… ┆ ./data/raw/beige-book/2020/01/… │\n",
       "│ 2020-03-01 00:00:00 ┆ This report was prepared at th… ┆ ./data/raw/beige-book/2020/03/… │\n",
       "│ 2020-04-01 00:00:00 ┆ This report was prepared at th… ┆ ./data/raw/beige-book/2020/04/… │\n",
       "│ 2020-05-01 00:00:00 ┆ Overall Economic Activity Econ… ┆ ./data/raw/beige-book/2020/05/… │\n",
       "└─────────────────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "# Get all summary files\n",
    "beige_book_files = glob.glob(\"./data/raw/beige-book/**/*-su.txt\", recursive=True)\n",
    "\n",
    "beige_book_data = []\n",
    "for file_path in beige_book_files:\n",
    "    # Extract date from filename (e.g. \"1971-01-su.txt\" -> \"1971-01\")\n",
    "    filename = Path(file_path).stem  # Gets filename without extension\n",
    "    date_str = filename.replace(\"-su\", \"\")\n",
    "    \n",
    "    try:\n",
    "        # Parse date \n",
    "        date = datetime.strptime(date_str, \"%Y-%m\")\n",
    "        \n",
    "        # Only include summaries after 2020\n",
    "        if date.year >= 2000:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                beige_book_data.append({\n",
    "                    \"date\": date,\n",
    "                    \"text\": text,\n",
    "                    \"filename\": file_path\n",
    "                })\n",
    "    except ValueError:\n",
    "        # Skip files that don't match expected date format\n",
    "        continue\n",
    "\n",
    "# Convert to polars DataFrame and sort by date\n",
    "beige_book_df = pl.DataFrame(beige_book_data).sort(\"date\")\n",
    "beige_book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_row(row):\n",
    "    g_analysis = gprompt_analyze({\"document\": row[\"text\"]})\n",
    "    g_analysis[\"source\"] = row['filename']  # type: ignore\n",
    "    g_analysis[\"month\"] = row[\"date\"].month\n",
    "    g_analysis[\"day\"] = row[\"date\"].day\n",
    "    g_analysis[\"year\"] = row[\"date\"].year\n",
    "    with open(\"./data/analyses-bb.jsonl\", \"a\") as f:\n",
    "        f.write(json.dumps(g_analysis) + \"\\n\")\n",
    "\n",
    "rows = list(beige_book_df.iter_rows(named=True))\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    executor.map(process_row, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(STATEMENT_FILE, \"rb\") as f:\n",
    "        statements = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    # Create new statements list if file doesn't exist\n",
    "    statements = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analyses from JSONL file\n",
    "analyses = []\n",
    "with open(\"./data/analyses-bb.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        analyses.append(json.loads(line))\n",
    "\n",
    "\n",
    "for g_analysis in analyses:\n",
    "    what_embeddings = model.encode(\n",
    "        [obs[\"what\"] for obs in g_analysis[\"observations\"]],\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    how_embeddings = model.encode(\n",
    "        [obs[\"how\"] for obs in g_analysis[\"observations\"]],\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    # Convert observations to Observation objects and add to statements\n",
    "    for i, obs in enumerate(g_analysis[\"observations\"]):\n",
    "        statement = Observation(\n",
    "            id=None,\n",
    "            what=obs[\"what\"],\n",
    "            what_embedding=what_embeddings[i],\n",
    "            how=obs[\"how\"],\n",
    "            how_embedding=how_embeddings[i],\n",
    "            citations=obs[\"citations\"],\n",
    "            source=g_analysis[\"source\"],\n",
    "            date=datetime.strptime(\n",
    "                f\"{g_analysis['year']}-{g_analysis['month']}-{g_analysis['day']}\",\n",
    "                \"%Y-%m-%d\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        statements.append(statement)\n",
    "\n",
    "\n",
    "# Save updated statements\n",
    "with open(STATEMENT_FILE, \"wb\") as f:\n",
    "    pickle.dump(statements, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
